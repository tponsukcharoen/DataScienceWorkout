{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Stopwatch Data Science: Two Sigma Financial Modeling Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this is a part of a Kaggle competition: Two Sigma Financial Modeling Challenge. For more information, see https://www.kaggle.com/c/two-sigma-financial-modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Ask a question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My objective is to the predict the value of unknown variable $y$, which is a time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I measure the performance by R-squared. It seems that the actual competition has online version of it for reinforcement learning. I will get back to it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Set the environment up and get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, set up a directory for data and link it to this workplace. Download data into your choice of directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import sys\n",
    "#reload(sys)\n",
    "#sys.setdefaultencoding(\"unicode\")\n",
    "\n",
    "#Set up the environment\n",
    "import numpy as np                         #Numpy\n",
    "import pandas as pd                        #Pandas\n",
    "import matplotlib.pyplot as plt            #Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Set up data directory\n",
    "DataDir = \"C:/Users/Admin/Documents/data/\"\n",
    "\n",
    "# Here's an example of loading the CSV using Pandas's built-in HDF5 support:\n",
    "with pd.HDFStore(DataDir+ \"train.h5\", \"r\") as train:\n",
    "    # Note that the \"train\" dataframe is the only dataframe in the file\n",
    "    df = train.get(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline                         \n",
    "#Make plot appeared inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore, Visualize, Clean, Transform, Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1710756, 111)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basis stats\n",
    "len(df), len(df.columns)   #number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#See all column names and types\n",
    "#print(df.dtypes.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#See first ten rows\n",
    "#df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#See last ten rows\n",
    "#df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here one can see something peculiar about this data. There are ids and timestamps. Let's check the number of unique elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1813, 1424)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"timestamp\"].unique()), len(df[\"id\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's create a summary table for those columns including type, min, mean, max, sigma, percent of zeros, and percent of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_column_summary = pd.DataFrame(df.dtypes,columns=['type'])\n",
    "df_column_summary.reset_index(inplace=True)\n",
    "df_column_summary['min'] = list(df.min())\n",
    "df_column_summary['mean'] = list(df.mean())\n",
    "df_column_summary['max'] = list(df.max())\n",
    "df_column_summary['sigma'] = list(df.std())\n",
    "\n",
    "l = ['NA'] * len(df.columns)\n",
    "for i in range(0,len(df.columns)):\n",
    "    l[i] = 1.0-np.count_nonzero(df.iloc[:,i])*1.0/len(df)\n",
    "df_column_summary['zero'] = l\n",
    "\n",
    "df_column_summary['missing'] = list(1.0-df.count()*1.0/len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              index     type           min          mean           max         sigma      zero   missing\n",
      "0                id    int16  0.000000e+00  1.093369e+03  2.158000e+03  6.306703e+02  0.000962  0.000000\n",
      "1         timestamp    int16  0.000000e+00  9.455825e+02  1.812000e+03  5.195463e+02  0.000438  0.000000\n",
      "2         derived_0  float32 -2.017497e+04 -4.536046e+00  3.252527e+03  2.497382e+02  0.000000  0.042647\n",
      "3         derived_1  float32 -7.375435e-02  7.729436e+11  1.068448e+16  7.620606e+13  0.000000  0.047364\n",
      "4         derived_2  float32 -9.848880e+03 -3.320328e-01  3.823001e+03  6.519810e+01  0.000000  0.233026\n",
      "5         derived_3  float32 -3.434176e+04 -5.046012e-01  1.239737e+03  1.020749e+02  0.000000  0.087371\n",
      "6         derived_4  float32 -8.551914e+03  1.801661e+01  6.785965e+04  9.258360e+02  0.000000  0.237590\n",
      "7     fundamental_0  float32 -2.344957e+00 -2.040938e-02  1.378195e+00  2.494859e-01  0.000000  0.013998\n",
      "8     fundamental_1  float32 -1.043737e+13 -5.703754e+08  5.203165e+02  7.502322e+10  0.000000  0.396941\n",
      "9     fundamental_2  float32 -1.077101e+03 -1.622954e-01  7.677125e+01  3.668149e+00  0.000000  0.215601\n",
      "10    fundamental_3  float32 -3.734025e-01  2.780239e-02  6.552332e+00  3.076004e-01  0.000000  0.265602\n",
      "11    fundamental_5  float32 -1.392729e-01  7.752405e-01  1.535051e+03  1.819782e+01  0.000000  0.562336\n",
      "12    fundamental_6  float32 -1.070270e+00  1.404761e-01  1.214948e+02  1.786976e+00  0.000000  0.410126\n",
      "13    fundamental_7  float32 -3.390085e-01  4.865615e+01  5.221653e+05  4.763797e+03  0.000000  0.015397\n",
      "14    fundamental_8  float32 -1.744283e-01  8.000651e-02  3.943310e+01  7.057598e-01  0.000000  0.218129\n",
      "15    fundamental_9  float32 -1.685835e+03 -8.617447e-02  3.965863e+01  1.114758e+01  0.000000  0.330595\n",
      "16   fundamental_10  float32 -8.453134e-02  4.418401e-01  3.454060e+02  4.330144e+00  0.000000  0.066039\n",
      "17   fundamental_11  float32 -7.505370e+02 -2.534907e-01  1.167478e+02  3.134663e+00  0.000000  0.215601\n",
      "18   fundamental_12  float32 -3.446150e-02  6.168341e+01  9.270403e+04  2.152291e+03  0.000000  0.064808\n",
      "19   fundamental_13  float32 -3.189299e-01  1.333553e-01  1.445207e+03  8.289918e+00  0.000000  0.207591\n",
      "20   fundamental_14  float32 -1.081379e-01  3.135854e+00  4.058832e+04  2.546490e+02  0.000000  0.208144\n",
      "21   fundamental_15  float32 -1.865915e-01  2.118761e-01  2.542647e+02  2.274582e+00  0.000000  0.207450\n",
      "22   fundamental_16  float32 -9.802253e+02 -2.115467e-01  8.544242e-01  8.346219e+00  0.000000  0.207591\n",
      "23   fundamental_17  float32 -3.636979e+16  7.087444e+13  1.040279e+18  8.059463e+15  0.000000  0.056830\n",
      "24   fundamental_18  float32 -1.695405e+03 -8.233162e-01  4.889408e+01  1.258578e+01  0.000000  0.009255\n",
      "25   fundamental_19  float32 -2.287757e+00  3.989280e-01  1.152071e+03  1.274384e+01  0.000000  0.031909\n",
      "26   fundamental_20  float32 -5.190238e+04 -1.480752e+00  1.782451e+03  2.664446e+02  0.000000  0.064808\n",
      "27   fundamental_21  float32 -1.870385e+00  9.907262e-02  3.505455e+00  3.223995e-01  0.000000  0.031760\n",
      "28   fundamental_22  float32 -3.518032e-01  6.140608e-02  2.690963e+02  1.750241e+00  0.000000  0.326457\n",
      "29   fundamental_23  float32 -1.840578e-01  2.740388e+01  1.438253e+05  1.316155e+03  0.000000  0.208518\n",
      "30   fundamental_24  float32 -6.850272e+01  7.610784e-02  2.873965e+01  7.024008e-01  0.000000  0.337076\n",
      "31   fundamental_25  float32 -3.127510e-01  1.693920e-01  3.665417e+02  3.007013e+00  0.000000  0.071252\n",
      "32   fundamental_26  float32 -2.669597e-01  2.169823e+02  3.271922e+06  2.563142e+04  0.000000  0.384148\n",
      "33   fundamental_27  float32 -2.276185e+00  4.224846e+00  8.776810e+03  1.589603e+02  0.000000  0.164429\n",
      "34   fundamental_28  float32 -4.014944e-01  4.284626e-02  4.753011e+00  3.614222e-01  0.000017  0.390080\n",
      "35   fundamental_29  float32 -3.387980e+00  5.558513e-01  1.046462e+04  6.051464e+01  0.000000  0.206988\n",
      "36   fundamental_30  float32 -6.891109e+01  6.634763e-02  3.586435e+01  1.316970e+00  0.000000  0.207456\n",
      "37   fundamental_31  float32 -3.965991e-01  9.953792e-02  1.494724e+03  8.906890e+00  0.000000  0.265602\n",
      "38   fundamental_32  float32 -7.015645e+02  3.315642e+01  4.820575e+04  1.126885e+03  0.000000  0.065276\n",
      "39   fundamental_33  float32 -5.081144e+00  6.165651e+02  5.081478e+06  5.477951e+04  0.000000  0.008087\n",
      "40   fundamental_34  float32 -2.330201e+03  1.918833e+00  7.796733e+03  5.990416e+01  0.000000  0.254193\n",
      "41   fundamental_35  float32 -2.518598e-01  3.489724e-01  2.696514e+02  3.560281e+00  0.000000  0.248122\n",
      "42   fundamental_36  float32 -1.466438e+03  2.671928e+01  3.020198e+05  2.644793e+03  0.000000  0.009261\n",
      "43   fundamental_37  float32 -3.245080e-01  1.483696e-01  6.840546e+01  1.188876e+00  0.000000  0.208003\n",
      "44   fundamental_38  float32 -1.693879e+00  4.936627e-02  8.043021e+00  5.142319e-01  0.000000  0.469669\n",
      "45   fundamental_39  float32 -1.357956e-01  2.712474e-01  6.672457e+02  4.436012e+00  0.000000  0.220706\n",
      "46   fundamental_40  float32 -5.204653e-01 -1.211397e-02  7.132049e-01  2.949136e-01  0.000000  0.163496\n",
      "47   fundamental_41  float32 -2.510341e+08 -4.696748e+02  5.829140e+07  7.626751e+05  0.000000  0.017603\n",
      "48   fundamental_42  float32 -1.614066e+08  1.322136e+02  3.747912e+07  6.407286e+05  0.000000  0.013393\n",
      "49   fundamental_43  float32 -1.146182e-01  2.344497e-01  2.494201e+01  8.593076e-01  0.000000  0.207236\n",
      "50   fundamental_44  float32 -1.831286e+00  1.720977e+00  2.708135e+04  1.636298e+02  0.000000  0.207981\n",
      "51   fundamental_45  float32 -1.878934e+03  1.468040e+00  5.471126e+04  2.728949e+02  0.000000  0.009389\n",
      "52   fundamental_46  float32 -2.372039e-01  1.867855e-01  1.506479e+03  8.645126e+00  0.000000  0.208003\n",
      "53   fundamental_47  float32 -3.137322e-01  6.526184e-02  5.283416e+00  3.709741e-01  0.000000  0.260895\n",
      "54   fundamental_48  float32 -2.980904e+03 -6.305848e-02  2.061773e+03  1.037661e+01  0.000000  0.009261\n",
      "55   fundamental_49  float32 -7.874931e-02  3.434145e-01  1.813291e+02  3.821147e+00  0.000000  0.326366\n",
      "56   fundamental_50  float32 -1.487149e+00  1.257884e+01  7.262396e+04  6.101042e+02  0.000000  0.207646\n",
      "57   fundamental_51  float32 -1.312815e+04  3.249429e-01  1.608102e+03  5.377707e+01  0.000000  0.261319\n",
      "58   fundamental_52  float32 -1.670013e-01  3.440971e-01  2.557487e+02  4.289630e+00  0.000000  0.089976\n",
      "59   fundamental_53  float32 -6.291855e+02 -1.666229e-01  6.172171e+01  5.299903e+00  0.000000  0.013998\n",
      "60   fundamental_54  float32 -2.777064e-01  1.882488e-01  3.486828e+00  4.009745e-01  0.000000  0.224587\n",
      "61   fundamental_55  float32 -2.224418e+02 -8.485153e-02  3.828660e+02  1.771217e+00  0.000000  0.215601\n",
      "62   fundamental_56  float32 -5.049634e+01  4.631519e-02  1.639057e+02  2.963386e+00  0.000000  0.215601\n",
      "63   fundamental_57  float32 -2.826288e-01  2.221422e-01  2.306051e+02  2.825126e+00  0.000000  0.384148\n",
      "64   fundamental_58  float32 -3.751944e-01  2.167122e-02  2.604494e+00  3.222283e-01  0.000000  0.083077\n",
      "65   fundamental_59  float32 -1.489624e-01  1.480153e-01  1.918350e+00  3.628329e-01  0.000000  0.009389\n",
      "66   fundamental_60  float32 -1.807738e-01  1.942597e-01  2.232580e+01  8.336142e-01  0.000000  0.207584\n",
      "67   fundamental_61  float32 -1.755816e-01  9.340944e+11  1.721357e+16  1.232967e+14  0.000000  0.392692\n",
      "68   fundamental_62  float32 -2.870304e+00 -5.293713e-02  2.717353e+00  5.039921e-01  0.019296  0.066039\n",
      "69   fundamental_63  float32 -3.298322e-01  1.522306e-01  2.588689e+00  3.576581e-01  0.000000  0.219560\n",
      "70      technical_0  float32 -1.000000e+00 -1.092023e-01  0.000000e+00  2.705369e-01  0.191331  0.011203\n",
      "71      technical_1  float32 -2.033571e-01  4.753915e-04  2.594056e-01  5.182010e-02  0.000000  0.074105\n",
      "72      technical_2  float32 -2.000000e+00 -9.030412e-01  0.000000e+00  8.563317e-01  0.016274  0.002501\n",
      "73      technical_3  float32 -2.673651e-01  1.216685e-03  3.380259e-01  6.332579e-02  0.000000  0.057456\n",
      "74      technical_5  float32 -1.789783e-01  7.961914e-04  2.084564e-01  4.372782e-02  0.000000  0.089787\n",
      "75      technical_6  float32 -2.000000e+00 -9.516839e-01  0.000000e+00  9.291667e-01  0.024031  0.002501\n",
      "76      technical_7  float32 -4.050815e-01  5.059733e-02  1.217279e+00  3.412927e-01  0.013099  0.001307\n",
      "77      technical_9  float32 -1.000000e+00 -2.304117e-02  0.000000e+00  1.312314e-01  0.635721  0.011203\n",
      "78     technical_10  float32 -2.000000e+00 -7.835972e-01  0.000000e+00  9.752976e-01  0.346737  0.097900\n",
      "79     technical_11  float32 -2.000000e+00 -9.217066e-01  0.000000e+00  8.877917e-01  0.015756  0.002501\n",
      "80     technical_12  float32 -1.000000e+00 -1.797370e-01  0.000000e+00  3.285517e-01  0.130918  0.011203\n",
      "81     technical_13  float32  0.000000e+00  2.925037e-04  7.339227e-03  6.044259e-04  0.663637  0.002785\n",
      "82     technical_14  float32 -2.000000e+00 -9.906582e-01  0.000000e+00  9.803746e-01  0.101017  0.008291\n",
      "83     technical_16  float32 -1.000000e+00 -1.316963e-03  1.000000e+00  1.293312e-01  0.731904  0.011680\n",
      "84     technical_17  float32 -2.000000e+00 -8.992432e-01  0.000000e+00  8.496431e-01  0.014380  0.002501\n",
      "85     technical_18  float32 -1.000000e+00 -3.190226e-02  0.000000e+00  1.517502e-01  0.506774  0.011700\n",
      "86     technical_19  float32 -3.363893e+00 -5.358487e-02  6.395316e+01  8.205566e-01  0.000000  0.001356\n",
      "87     technical_20  float32  0.000000e+00  1.453731e-03  6.784815e-02  2.873302e-03  0.666117  0.002785\n",
      "88     technical_21  float32 -6.085453e+00 -1.294733e-02  1.029848e+03  2.251926e+00  0.000000  0.001307\n",
      "89     technical_22  float32 -5.000000e-01 -4.858378e-03  5.000000e-01  4.081269e-01  0.333627  0.000000\n",
      "90     technical_24  float32 -3.149068e-01  2.538206e-03  4.352512e-01  8.140622e-02  0.000000  0.041587\n",
      "91     technical_25  float32 -1.392135e-01  6.203377e-04  1.579077e-01  3.357598e-02  0.000000  0.121616\n",
      "92     technical_27  float32 -2.204653e+00 -7.586388e-02  2.180798e+01  6.748320e-01  0.000000  0.001415\n",
      "93     technical_28  float32 -1.081794e-01  6.762877e-04  1.339475e-01  2.681121e-02  0.000000  0.153684\n",
      "94     technical_29  float32 -2.000000e+00 -9.098050e-01  0.000000e+00  9.914070e-01  0.213687  0.036016\n",
      "95     technical_30  float32  0.000000e+00  1.245941e-03  7.195023e-02  2.824704e-03  0.664676  0.002785\n",
      "96     technical_31  float32 -1.533395e-01  2.513260e-04  2.014349e-01  3.808616e-02  0.000000  0.106782\n",
      "97     technical_32  float32 -1.000000e+00 -8.669098e-02  0.000000e+00  2.424043e-01  0.253228  0.011203\n",
      "98     technical_33  float32 -5.471164e-01  1.754952e-02  1.322735e+00  1.875426e-01  0.000000  0.008496\n",
      "99     technical_34  float32 -5.000000e-01 -5.813219e-04  5.000000e-01  4.086673e-01  0.331963  0.000000\n",
      "100    technical_35  float32 -1.379302e+00 -1.033000e-01  1.464272e+01  5.522224e-01  0.000000  0.001844\n",
      "101    technical_36  float32 -1.687572e+00 -8.584833e-02  4.957758e+01  6.125852e-01  0.000000  0.001492\n",
      "102    technical_37  float32 -1.000000e+00 -9.103397e-02  0.000000e+00  2.471038e-01  0.231378  0.011203\n",
      "103    technical_38  float32 -1.000000e+00 -8.156685e-02  0.000000e+00  2.346534e-01  0.251298  0.011203\n",
      "104    technical_39  float32 -1.000000e+00 -7.287001e-02  0.000000e+00  2.235729e-01  0.280264  0.011700\n",
      "105    technical_40  float32 -5.250904e-01  4.908321e-02  1.569265e+00  3.102316e-01  0.000000  0.001307\n",
      "106    technical_41  float32 -4.449529e-01  5.236218e-03  6.844833e-01  1.133733e-01  0.000000  0.025830\n",
      "107    technical_42  float32 -1.000000e+00 -1.699966e-02  1.000000e+00  2.116284e-01  0.366580  0.011691\n",
      "108    technical_43  float32 -2.000000e+00 -9.735299e-01  0.000000e+00  9.605551e-01  0.049472  0.002739\n",
      "109    technical_44  float32 -1.265686e-01  3.881475e-04  1.435858e-01  3.011983e-02  0.000000  0.138406\n",
      "110               y  float32 -8.609413e-02  2.217509e-04  9.349781e-02  2.240643e-02  0.000009  0.000000\n"
     ]
    }
   ],
   "source": [
    "print(df_column_summary.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some lessons from data summary:\n",
    "\n",
    "1. It makes sense to treat this id as an object rather than int to avoid the sense of ordering. \n",
    "2. In terms of sigma (together with other measures), one can spot a strange large number in many features. Worth taking a look.\n",
    "3. In terms of max and min, one can spot discreteness in many features. It may be non-numerical. Worth taking a look.\n",
    "4. In terms of zero values, one should aware that zero may mean missing values. It is also associated with a discrete feature.\n",
    "5. In terms of missing values, there is nothing to worry yet. No significant poor features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's further investigate each feature using visualization tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Play around with interactive visualization tool. However, due to large amount of data. Let's use simple one instead.\n",
    "#from bokeh.plotting import figure, output_notebook, show\n",
    "#output_notebook()\n",
    "\n",
    "#i = 0\n",
    "#p = figure(title=df.columns[i], width=500, height=500)\n",
    "#p.circle(df[df.columns[i]], df['y'], size=7, color=\"firebrick\", alpha=0.5)\n",
    "#show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the notes above, we should look into feature 3, 8, 23, 67 (large sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2-d array plots\n",
    "#l = [3, 8, 23, 67]\n",
    "#f, axarr = plt.subplots(1, 4, figsize=(4*4,3*1))\n",
    "#num = 0\n",
    "#for i in l:\n",
    "#    axarr[num].scatter(df[df.columns[i]],df['y'])\n",
    "#    axarr[num].set_title(str(i))\n",
    "#    num = num + 1\n",
    "                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the notes above, we should look into feature 70, 72, 75, 77, 78, 79, 80, 82, 83, 84, 85, 89, 94, 97, 99, 102, 103, 104, 107, 108 (discrete max/min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2-d array plots\n",
    "#l = [70, 72, 75, 77, 78, 79, 80, 82, 83, 84, 85, 89, 94, 97, 99, 102, 103, 104, 107, 108]\n",
    "#f, axarr = plt.subplots(5, 4, figsize=(4*4,3*5))\n",
    "#num = 0\n",
    "#for i in l:\n",
    "#    axarr[num/4,num%4].scatter(df[df.columns[i]],df['y'])\n",
    "#    axarr[num/4,num%4].set_title(str(i))\n",
    "#    num = num + 1\n",
    "                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the notes above, we should look into feature (70), (77), (78), (80), 81, (82), (83), 85, 87, (89), 94, 95, (97), (99), (102), (103), (104), (107) (# of zeros > 10 percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2-d array plots\n",
    "#l =  [81, 85, 87, 94, 95]\n",
    "#f, axarr = plt.subplots(2, 4, figsize=(4*4,3*2))\n",
    "#num = 0\n",
    "#for i in l:\n",
    "#    axarr[num/4,num%4].scatter(df[df.columns[i]],df['y'])\n",
    "#    axarr[num/4,num%4].set_title(str(i))\n",
    "#    num = num + 1\n",
    "                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These features do not give a strong signal but it looks fine. There are only two discrete features 89 and 99. Sinee they are set to be decimal points, let's believe that there are ordering features. So, there is nothing to worry for now.\n",
    "\n",
    "Let's normalize data so that each feature has 0-mean and 1-std (except id, timestamp, and input). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#One may use sklearn to do this, but the trouble is we need to deal with NA values, which is annoying. So just do it from scratch.\n",
    "#from sklearn.preprocessing import normalize\n",
    "#X = normalize(np.array(df[df.columns[range(2,110)]].dropna(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(2,110):\n",
    "    mean = df_column_summary.loc[i,'mean']\n",
    "    sigma = df_column_summary.loc[i,'sigma']\n",
    "    df[df.columns[i]] = (df[df.columns[i]]-mean)/sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's look at possible dimensionality reduction for features (except id, timestamp, and output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's try PCA\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.32672635  0.27849502  0.27681062  0.1114164   0.00655162]\n"
     ]
    }
   ],
   "source": [
    "#try group them according to feature types: derived\n",
    "X = np.array(df[df.columns[range(2,7)]].dropna(axis=0))\n",
    "pca_derived = PCA(n_components=5)\n",
    "pca_derived.fit(X)\n",
    "print(pca_derived.explained_variance_ratio_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.25558325  0.13097034  0.10843365  0.06818235  0.06199728  0.05705869\n",
      "  0.04216031  0.03775116  0.03570373  0.03272416  0.02860421  0.02629839\n",
      "  0.02333962  0.02214361  0.01652564  0.01068863  0.00874587  0.00707701\n",
      "  0.00565645  0.00433277]\n"
     ]
    }
   ],
   "source": [
    "#try group them according to feature types: fundamental\n",
    "X = np.array(df[df.columns[range(7,70)]].dropna(axis=0))\n",
    "pca_fundamental = PCA(n_components=20)\n",
    "pca_fundamental.fit(X)\n",
    "print(pca_fundamental.explained_variance_ratio_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.144173    0.08449022  0.05374959  0.04201616  0.03940461  0.03401835\n",
      "  0.02991891  0.02958015  0.02731697  0.02642108  0.02606273  0.02566239\n",
      "  0.02549551  0.0254263   0.02527166  0.02518373  0.02511065  0.02498515\n",
      "  0.02477049  0.02456923  0.0228427   0.02177022  0.02136387  0.01724815\n",
      "  0.01452915  0.01372289  0.01339999  0.01210162  0.0116663   0.0110958\n",
      "  0.01007953  0.00972421  0.00956461  0.00916052  0.00891192  0.00738879\n",
      "  0.00706167  0.00642801  0.00502863  0.00328453]\n"
     ]
    }
   ],
   "source": [
    "#try group them according to feature types: technical\n",
    "X = np.array(df[df.columns[range(70,110)]].dropna(axis=0))\n",
    "pca_technical = PCA(n_components=40)\n",
    "pca_technical.fit(X)\n",
    "print(pca_technical.explained_variance_ratio_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a rule of thumbs, say, we want to capture at least 95% variance ratio. For 'derived', we need 4 out of 5 components. For 'fundamental', we need 16 out of 63 components. For 'technical', we need 32 out of 40 components.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with PCA is that we need to deal with NA values. If we want to continue analysis with PCA, we may \n",
    "\n",
    "1. fill NA with zero (mean) and continue with full number of rows. \n",
    "2. delete rows with NA and proceed.\n",
    "\n",
    "Since there are many NAs in data, let's try option 1 and see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#CLEAN\n",
    "#replace NaN values with zero (mean).\n",
    "df = df.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'y'], dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d5.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TRANFORM/ NEW VARIABLES\n",
    "'''\n",
    "#Apply PCA to different group of features and reattached everything\n",
    "d1 = df[['id','timestamp']]\n",
    "#derived\n",
    "d2 = pd.DataFrame(pca_derived.transform(df[df.columns[range(2,7)]]))\n",
    "d2 = d2.loc[:,0:3]\n",
    "d2.columns = ['derived_pca_1','derived_pca_2','derived_pca_3','derived_pca_4']\n",
    "\n",
    "d3 = pd.DataFrame(pca_fundamental.transform(df[df.columns[range(7,70)]]))\n",
    "d3 = d3.loc[:,0:15]\n",
    "d3.columns = ['fundamental_pca_' + str(i) for i in range(0,16)]\n",
    "\n",
    "d4 = pd.DataFrame(pca_technical.transform(df[df.columns[range(70,110)]]))\n",
    "d4 = d4.loc[:,0:31]\n",
    "d4.columns = ['technical_pca_' + str(i) for i in range(0,32)]\n",
    "\n",
    "d5 = df[['y']]\n",
    "\n",
    "df = pd.concat([d1,d2,d3,d4,d5])\n",
    "'''\n",
    "#It seems that using this new data, the model suffers from too much information. We need new ways to address this issue.\n",
    "\n",
    "# Convert ID to be object, not a number\n",
    "df['id'] = df['id'].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4: Model the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have prepared data for validation as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now test/train split by random selection. Ideally, we should do cross-validation and parameter average, but save it for later.\n",
    "r = np.random.uniform(0,1,len(df)) # Random UNIForm numbers, one per row\n",
    "train = df[ r < 0.7]\n",
    "test = df[0.7 <= r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1197427, 513329)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try something simple that accommodate non-number types: trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Random forest\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "X_train = train.drop('y', axis=1)\n",
    "y_train = train['y']\n",
    "X_test = test.drop('y', axis=1)\n",
    "y_test = test['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clf = RandomForestRegressor()\n",
    "#clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Took too much time to respond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the plan. Let's do something called grand PCA. That is, we make one row to represent each timestamp. Then we perform PCA from there on both inputs and outputs. Then see how it goes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note to myself*: The code does not work (memory and speed issue). I spent roughly 2 Pomodoros. Let's restart tomorrow."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
