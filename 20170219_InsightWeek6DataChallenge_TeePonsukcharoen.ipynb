{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Stopwatch Data Science: Week 6 DS Challenge from Insight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this is a part of Insight Data Science. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Ask a question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My objective is to develop a model that predicts whether a biopsied breast cell is benign (not cancerous) or malignant (cancerous), given a set of attributes about the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I measure the performance by..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I get data from the data available [here](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data). The following shows imports and variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up the environment\n",
    "import numpy as np                         #Numpy\n",
    "import pandas as pd                        #Pandas\n",
    "import matplotlib.pyplot as plt            #Plot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Set up data directory\n",
    "DataDir = \"C:/Users/Admin/Documents/data/\"\n",
    "\n",
    "# Here's an example of loading the CSV using Pandas's built-in HDF5 support:\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(DataDir + 'breast-cancer-wisconsin.data',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore, Visualize, Clean, Transform, Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, data has no header. We need to make it up. In the problem, the info is given as follow:\n",
    "\n",
    "1. Sample code number: id number \n",
    "2. Clump Thickness: 1 - 10 \n",
    "3. Uniformity of Cell Size: 1 - 10 \n",
    "4. Uniformity of Cell Shape: 1 - 10 \n",
    "5. Marginal Adhesion: 1 - 10 \n",
    "6. Single Epithelial Cell Size: 1 - 10 \n",
    "7. Bare Nuclei: 1 - 10 \n",
    "8. Bland Chromatin: 1 - 10 \n",
    "9. Normal Nucleoli: 1 - 10 \n",
    "10. Mitoses: 1 - 10 \n",
    "11. Class: (2 for benign, 4 for malignant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rename the columns accordingly. Since all features are foreign to me, I will name them as X1 up to X9 (except ID and Class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns = ['ID','X1','X2','X3','X4','X5','X6','X7','X8','X9','y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  X1  X2  X3  X4  X5  X6  X7  X8  X9  y\n",
       "0  1000025   5   1   1   1   2   1   3   1   1  2\n",
       "1  1002945   5   4   4   5   7  10   3   2   1  2\n",
       "2  1015425   3   1   1   1   2   2   3   1   1  2\n",
       "3  1016277   6   8   8   1   3   4   3   7   1  2\n",
       "4  1017023   4   1   1   3   2   1   3   1   1  2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>776715</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>841769</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>888820</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  X1  X2  X3  X4  X5 X6  X7  X8  X9    y\n",
       "694  776715   3   1   1   1   3  2   1   1   1  0.0\n",
       "695  841769   2   1   1   1   2  1   1   1   1  0.0\n",
       "696  888820   5  10  10   3   7  3   8  10   2  1.0\n",
       "697  897471   4   8   6   4   3  4  10   6   1  1.0\n",
       "698  897471   4   8   8   5   4  5  10   4   1  1.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transform value of y: 2 -> 0 and 4 -> 1 to follow the convention of the classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['y'] = df['y']*0.5-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have run basic checks on data as follow ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore data a bit. First, size and the number of each y's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699, 458, 241)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df), np.sum(df['y']==0), np.sum(df['y']==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is somewhat imbalanced, but not severely imbalanced.`\n",
    "\n",
    "Next, let's check if we face a problem of missing values. Fortunately, there is no problem with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df['X9'].isnull()) #Run for all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's check the distribution of each feature along with the relationship with y. We can do this visually since there are not many features anyway. We can see that all features are quite strong. (I don't why I can't see X6 though). It seems that the benign ones tend to have small feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  15.,    9.,   16.,   13.,   20.,    4.,    7.,   19.,    9.,  129.]),\n",
       " array([  1. ,   1.9,   2.8,   3.7,   4.6,   5.5,   6.4,   7.3,   8.2,\n",
       "          9.1,  10. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAFkCAYAAABIPLOYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSJKkygwOkiSpMoODJEmq7P8DtLfdSzOgpwYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe663ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_name = 'X6'\n",
    "plt.hist(df[column_name][df['y']==0],alpha = 0.5)\n",
    "plt.hist(df[column_name][df['y']==1],alpha = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is something wrong with X6. Other features are all numbers only X6 has '?'. Let's replace them with the mean of known values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = np.mean(df['X6'][df['X6']!='?'].map(lambda x: int(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(df)):\n",
    "    if df.loc[i,'X6'] == '?':\n",
    "        df.loc[i,'X6'] = m\n",
    "    else:\n",
    "        df.loc[i,'X6'] = int(df.loc[i,'X6'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is suspicious that these features are highly correlated because of the visualization above. Let's check out the correlation among features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm0AAAH4CAYAAAAYSNrTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe83e588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Correlation matrix\n",
    "CorrMatrix = df[['X1','X2','X3','X4','X5','X6','X7','X8','X9']].corr()\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax1  = fig.add_subplot(111)\n",
    "\n",
    "plt.imshow(CorrMatrix.T, cmap='copper', interpolation='nearest',aspect='auto')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature X2 and X3 seems correlated. The rest is not strongly correlated. We can try PCA to see in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.68897023,  0.07271567,  0.06098953,  0.04436764,  0.03902387,\n",
       "        0.0345756 ,  0.02528331,  0.02267603,  0.01139812])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('scaling', StandardScaler()), ('pca', PCA(n_components=9))])\n",
    "pipeline.fit(df[['X1','X2','X3','X4','X5','X6','X7','X8','X9']])\n",
    "pca.explained_variance_ratio_#pipeline.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may throw away some features out, but it might not be worth. Just stick with all features then."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no feature engineering at this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4: Model the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have prepared data for validation as follow: For simplicity, just do 70/30 train/test. Make sure that we have both 0 and 1 in both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_0 = df[df['y']==0]\n",
    "df_1 = df[df['y']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = np.random.uniform(0,1, len(df_0))\n",
    "train_0 = df_0[r<0.7]\n",
    "test_0 = df_0[r>=0.7]\n",
    "r = np.random.uniform(0,1, len(df_1))\n",
    "train_1 = df_1[r<0.7]\n",
    "test_1 = df_1[r>=0.7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it is not well balanced. Let's fix this issue later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.concat([train_0, train_1])\n",
    "test = pd.concat([test_0, test_1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a simple model with easy interpretation: **Logistic regression**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.96721311475409832, 0.976303317535545]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, y = train[['X1','X2','X3','X4','X5','X6','X7','X8','X9']], train['y']\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "Model = LogisticRegressionCV(penalty='l2') #Equipped with built-in CV\n",
    "\n",
    "m = Model.fit(X, y)\n",
    "\n",
    "Xtest, ytest = test[['X1','X2','X3','X4','X5','X6','X7','X8','X9']], test['y']\n",
    "Xtest = StandardScaler().fit_transform(Xtest)\n",
    "\n",
    "[m.score(X, y), m.score(Xtest, ytest)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is surprisingly good. Let's fix the problem of unbalanced training data by over sample the the data with 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458, 241)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_0), len(df_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add another p = (485-241)/241  portion of lines of data with 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.900414937759\n"
     ]
    }
   ],
   "source": [
    "p = (len(df_0)-len(df_1))*1.0/len(df_1)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = np.random.uniform(0,1, len(train_1))\n",
    "train_2 = train_1[r<p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.concat([train_0, train_1, train_2])\n",
    "test = pd.concat([test_0, test_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.95968992248062013, 0.95734597156398105]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, y = train[['X1','X2','X3','X4','X5','X6','X7','X8','X9']], train['y']\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "Model = LogisticRegressionCV(penalty='l2') #Equipped with built-in CV\n",
    "\n",
    "m = Model.fit(X, y)\n",
    "\n",
    "Xtest, ytest = test[['X1','X2','X3','X4','X5','X6','X7','X8','X9']], test['y']\n",
    "Xtest = StandardScaler().fit_transform(Xtest)\n",
    "\n",
    "[m.score(X, y), m.score(Xtest, ytest)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's try number of methods at once. Some of them are ensemble methods, say, random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Nearest Neighbors', 0.9875968992248062, 0.94312796208530802)\n",
      "('Linear SVM', 0.97054263565891474, 0.96208530805687209)\n",
      "('RBF SVM', 1.0, 0.86729857819905209)\n",
      "('Gaussian Process', 0.9751937984496124, 0.95734597156398105)\n",
      "('Decision Tree', 0.98449612403100772, 0.91469194312796209)\n",
      "('Random Forest', 0.98294573643410854, 0.93364928909952605)\n",
      "('Neural Net', 0.9751937984496124, 0.95734597156398105)\n",
      "('AdaBoost', 0.99069767441860468, 0.92417061611374407)\n",
      "('Naive Bayes', 0.95968992248062013, 0.92890995260663511)\n",
      "('QDA', 0.95193798449612399, 0.93364928909952605)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, y = train[['X1','X2','X3','X4','X5','X6','X7','X8','X9']], train['y']\n",
    "X = StandardScaler().fit_transform(X)\n",
    "Xtest, ytest = test[['X1','X2','X3','X4','X5','X6','X7','X8','X9']], test['y']\n",
    "Xtest = StandardScaler().fit_transform(Xtest)\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X, y)\n",
    "    print(name, clf.score(X, y), clf.score(Xtest, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here one can see that the complicated methods do not pay off well. The logistic regression already did the job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One concern, however, is that the score used here is the mean accuracy. In this particular problem, we are more interested in other measures such as area under the curve, precision and recall. Let's dig into that by revisiting the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.95968992248062013, 0.95734597156398105]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, y = train[['X1','X2','X3','X4','X5','X6','X7','X8','X9']], train['y']\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "Model = LogisticRegressionCV(penalty='l2') #Equipped with built-in CV\n",
    "\n",
    "m = Model.fit(X, y)\n",
    "\n",
    "Xtest, ytest = test[['X1','X2','X3','X4','X5','X6','X7','X8','X9']], test['y']\n",
    "Xtest = StandardScaler().fit_transform(Xtest)\n",
    "\n",
    "[m.score(X, y), m.score(Xtest, ytest)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's look at the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def PrecisionAndRecall(XX,yy,model):\n",
    "    result = pd.DataFrame(yy) \n",
    "    result['ypredict'] = model.predict(XX)\n",
    "    TP = np.sum((result['y']==1)&(result['ypredict']==1))\n",
    "    TN = np.sum((result['y']==0)&(result['ypredict']==0))\n",
    "    FP = np.sum((result['y']==0)&(result['ypredict']==1))\n",
    "    FN = np.sum((result['y']==1)&(result['ypredict']==0))\n",
    "    precision = TP*1.0/(TP+FP)\n",
    "    recall = TP*1.0/(TP+FN)\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.95770392749244715, 0.96352583586626139), (0.88461538461538458, 1.0))"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PrecisionAndRecall(X,y,m), PrecisionAndRecall(Xtest,ytest,m) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our linear model worked nicely. Note that we prefer recall to be high since capturing all cancers is important. That is, it is OK to have some false positive as long as we can capture all cancer cells. Let's see how precision and recall are for more sophisticated models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Nearest Neighbors', (0.97626112759643913, 1.0), (0.85185185185185186, 1.0))\n",
      "('Linear SVM', (0.9668674698795181, 0.9756838905775076), (0.89610389610389607, 1.0))\n",
      "('RBF SVM', (1.0, 1.0), (0.71134020618556704, 1.0))\n",
      "('Gaussian Process', (0.96996996996996998, 0.98176291793313075), (0.88461538461538458, 1.0))\n",
      "('Decision Tree', (0.97050147492625372, 1.0), (0.7931034482758621, 1.0))\n",
      "('Random Forest', (0.96745562130177509, 0.99392097264437695), (0.84146341463414631, 1.0))\n",
      "('Neural Net', (0.96996996996996998, 0.98176291793313075), (0.88461538461538458, 1.0))\n",
      "('AdaBoost', (0.98791540785498488, 0.99392097264437695), (0.8271604938271605, 0.97101449275362317))\n",
      "('Naive Bayes', (0.94690265486725667, 0.9756838905775076), (0.8214285714285714, 1.0))\n",
      "('QDA', (0.93313953488372092, 0.9756838905775076), (0.83132530120481929, 1.0))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, y = train[['X1','X2','X3','X4','X5','X6','X7','X8','X9']], train['y']\n",
    "X = StandardScaler().fit_transform(X)\n",
    "Xtest, ytest = test[['X1','X2','X3','X4','X5','X6','X7','X8','X9']], test['y']\n",
    "Xtest = StandardScaler().fit_transform(Xtest)\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X, y)\n",
    "    score = clf.score(X, y)\n",
    "    print(name, PrecisionAndRecall(X,y,clf), PrecisionAndRecall(Xtest,ytest,clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here one can see that more sophisticated models did not do a better job than the logistic regression. The last shot model is to \"ensemble\" all models together. We use the prediction to to vote. If vote is equal, we round it to 1 since we have a high recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BigVote = pd.DataFrame(m.predict(Xtest),columns = ['Logistic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X, y)\n",
    "    BigVote[name] = clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.87341772151898733, 1.0)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(BigVote.mean(axis=1).map(lambda x: int(x>=0.5)), columns = ['ypredict'])\n",
    "result['y'] = list(ytest)\n",
    "TP = np.sum((result['y']==1)&(result['ypredict']==1))\n",
    "TN = np.sum((result['y']==0)&(result['ypredict']==0))\n",
    "FP = np.sum((result['y']==0)&(result['ypredict']==1))\n",
    "FN = np.sum((result['y']==1)&(result['ypredict']==0))\n",
    "precision = TP*1.0/(TP+FP)\n",
    "recall = TP*1.0/(TP+FN)\n",
    "precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It sounds good but might overkill. Let's use simply the logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 5: Communicate the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have concluded that the logistic regression is the best model with following performance:\n",
    "\n",
    "On the test set: accuracy 96%, precision 88%, recall 100%\n",
    "\n",
    "Note: We HAVE perform cross-validation in the training data. It means that our model is quite resilient to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02109208,  0.02335282,  0.02341951,  0.01950902,  0.01830815,\n",
       "         0.02392969,  0.02139421,  0.01933462,  0.01073013]])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients shows that the higher value in all features leads to a higher chance of cancer (malignant). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What's next?** We haven't invested our time on the area under curve. We also haven't thought about other ensemble methods like Boosting. It is also good to check where the classification goes wrong. Plotting may give us and idea how to go beyond a linear model in a data-driven way rather than trial and errors like we have done."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
